{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1821063e",
   "metadata": {},
   "source": [
    "# Тема “Обучение с учителем”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da66606",
   "metadata": {},
   "source": [
    "## Задание 1\n",
    "Импортируйте библиотеки pandas и numpy.\n",
    "\n",
    "Загрузите \"Boston House Prices dataset\" из встроенных наборов данных библиотеки sklearn. \n",
    "Создайте датафреймы X и y из этих данных.\n",
    "\n",
    "Разбейте эти датафреймы на тренировочные (X_train, y_train) и тестовые (X_test, y_test) с помощью функции train_test_split так, чтобы размер тестовой выборки\n",
    "составлял 30% от всех данных, при этом аргумент random_state должен быть равен 42.\n",
    "\n",
    "Создайте модель линейной регрессии под названием lr с помощью класса LinearRegression из модуля sklearn.linear_model.\n",
    "\n",
    "Обучите модель на тренировочных данных (используйте все признаки) и сделайте предсказание на тестовых.\n",
    "\n",
    "Вычислите R2 полученных предказаний с помощью r2_score из модуля sklearn.metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3e2bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c25ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27eabb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "\n",
    "boston.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbde1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = boston[\"data\"]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9905d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = boston[\"feature_names\"]\n",
    "\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941a4821",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(boston[\"DESCR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d007af",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = boston[\"target\"]\n",
    "\n",
    "target[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f4d420",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(data, columns=feature_names)\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e1ae38",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.DataFrame(target, columns=[\"price\"])\n",
    "\n",
    "y.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13e991a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b403d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81b06c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6af6966",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea00fa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47b4fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090ccb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lr = lr.predict(X_test)\n",
    "check_test_lr = pd.DataFrame({\n",
    "    \"y_test\": y_test[\"price\"], \n",
    "    \"y_pred_lr\": y_pred_lr.flatten()})\n",
    "\n",
    "check_test_lr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b1eebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mean_squared_error_lr = mean_squared_error(check_test_lr[\"y_pred_lr\"], check_test_lr[\"y_test\"])\n",
    "print(mean_squared_error_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d745e80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d85dc2bc",
   "metadata": {},
   "source": [
    "## Задание 2\n",
    "Создайте модель под названием model с помощью RandomForestRegressor из модуля sklearn.ensemble.\n",
    "\n",
    "Сделайте агрумент n_estimators равным 1000,\n",
    "max_depth должен быть равен 12 и random_state сделайте равным 42.\n",
    "\n",
    "Обучите модель на тренировочных данных аналогично тому, как вы обучали модель LinearRegression,\n",
    "но при этом в метод fit вместо датафрейма y_train поставьте y_train.values[:, 0],\n",
    "чтобы получить из датафрейма одномерный массив Numpy,\n",
    "так как для класса RandomForestRegressor в данном методе для аргумента y предпочтительно применение массивов вместо датафрейма.\n",
    "\n",
    "Сделайте предсказание на тестовых данных и посчитайте R2. Сравните с результатом из предыдущего задания.\n",
    "\n",
    "Напишите в комментариях к коду, какая модель в данном случае работает лучше.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84670b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcf296e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestRegressor(n_estimators=1000, max_depth=12, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d686c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train.values[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a16a298",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_clf = clf.predict(X_test)\n",
    "check_test_clf = pd.DataFrame({\n",
    "    \"y_test\": y_test[\"price\"], \n",
    "    \"y_pred_clf\": y_pred_clf.flatten()})\n",
    "\n",
    "check_test_clf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd18d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error_clf = mean_squared_error(check_test_clf[\"y_pred_clf\"], check_test_clf[\"y_test\"])\n",
    "print(mean_squared_error_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e1fbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_squared_error_lr, mean_squared_error_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7359b519",
   "metadata": {},
   "source": [
    "Алгоритм  класса LinearRegression по сравнению с RandomForestRegressor показывает результаты точнее более, чем в 2 раза."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a1153d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d4f31d3",
   "metadata": {},
   "source": [
    "## *Задание 3\n",
    "\n",
    "Вызовите документацию для класса RandomForestRegressor,\n",
    "найдите информацию об атрибуте feature_importances_.\n",
    "\n",
    "С помощью этого атрибута найдите сумму всех показателей важности,\n",
    "установите, какие два признака показывают наибольшую важность.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393e958e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "?RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e96dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7955abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(clf.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6639d211",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame({'name':X.columns, \n",
    "                                   'feature_importance':clf.feature_importances_}, \n",
    "                                  columns=['feature_importance', 'name'])\n",
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086a87e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance.nlargest(2, 'feature_importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664f7e21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ac36c80",
   "metadata": {},
   "source": [
    "## *Задание 4\n",
    "\n",
    "В этом задании мы будем работать с датасетом, с которым мы уже знакомы по домашнему заданию по библиотеке Matplotlib, это датасет Credit Card Fraud Detection.Для этого датасета мы будем решать задачу классификации - будем определять,какие из транзакциции по кредитной карте являются мошенническими.Данный датасет сильно несбалансирован (так как случаи мошенничества относительно редки),так что применение метрики accuracy не принесет пользы и не поможет выбрать лучшую модель.Мы будем вычислять AUC, то есть площадь под кривой ROC.\n",
    "\n",
    "Импортируйте из соответствующих модулей RandomForestClassifier, GridSearchCV и train_test_split.\n",
    "\n",
    "Загрузите датасет creditcard.csv и создайте датафрейм df.\n",
    "\n",
    "С помощью метода value_counts с аргументом normalize=True убедитесь в том, что выборка несбалансирована. Используя метод info, проверьте, все ли столбцы содержат числовые данные и нет ли в них пропусков.Примените следующую настройку, чтобы можно было просматривать все столбцы датафрейма:\n",
    "\n",
    "pd.options.display.max_columns = 100.\n",
    "\n",
    "Просмотрите первые 10 строк датафрейма df.\n",
    "\n",
    "Создайте датафрейм X из датафрейма df, исключив столбец Class.\n",
    "\n",
    "Создайте объект Series под названием y из столбца Class.\n",
    "\n",
    "Разбейте X и y на тренировочный и тестовый наборы данных при помощи функции train_test_split, используя аргументы: test_size=0.3, random_state=100, stratify=y.\n",
    "У вас должны получиться объекты X_train, X_test, y_train и y_test.\n",
    "\n",
    "Просмотрите информацию о их форме.\n",
    "\n",
    "Для поиска по сетке параметров задайте такие параметры:\n",
    "parameters = [{'n_estimators': [10, 15],\n",
    "'max_features': np.arange(3, 5),\n",
    "'max_depth': np.arange(4, 7)}]\n",
    "\n",
    "Создайте модель GridSearchCV со следующими аргументами:\n",
    "estimator=RandomForestClassifier(random_state=100),\n",
    "param_grid=parameters,\n",
    "scoring='roc_auc',\n",
    "cv=3.\n",
    "\n",
    "Обучите модель на тренировочном наборе данных (может занять несколько минут).\n",
    "\n",
    "Просмотрите параметры лучшей модели с помощью атрибута best_params_.\n",
    "\n",
    "Предскажите вероятности классов с помощью полученнной модели и метода predict_proba.\n",
    "\n",
    "Из полученного результата (массив Numpy) выберите столбец с индексом 1 (вероятность класса 1) и запишите в массив y_pred_proba.\n",
    "Из модуля sklearn.metrics импортируйте метрику roc_auc_score.\n",
    "\n",
    "Вычислите AUC на тестовых данных и сравните с результатом,полученным на тренировочных данных, используя в качестве аргументов массивы y_test и y_pred_proba.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10de47e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52ad20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '../Урок6/creditcard.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa11428a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATASET_PATH, sep=',')\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c33de0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Class'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cca053",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc95ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e68b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0dcc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Class', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743bd104",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.Series(df['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f88fec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=100, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5003ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cb0ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [{\n",
    "    'n_estimators': [10, 15], \n",
    "    'max_features': np.arange(3, 5), \n",
    "    'max_depth': np.arange(4, 7)\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e4bdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=100),\n",
    "    param_grid=parameters,\n",
    "    scoring='roc_auc',\n",
    "    cv=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286b29ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522f340a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c18c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(max_depth=6, max_features=3, n_estimators=15)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b59fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = clf.predict_proba(X_test)[:, 1]\n",
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00aba0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a2c0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cb9b70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "038c7f0b",
   "metadata": {},
   "source": [
    "## *Дополнительные задания:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9df25e",
   "metadata": {},
   "source": [
    "1). Загрузите датасет Wine из встроенных датасетов sklearn.datasets с помощью функции load_wine в переменную data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee14ef0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "data = load_wine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357558fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da8e6b4d",
   "metadata": {},
   "source": [
    "2). Полученный датасет не является датафреймом. Это структура данных, имеющая ключи аналогично словарю. Просмотрите тип данных этой структуры данных и создайте список data_keys, содержащий ее ключи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b462f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1259c6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa434c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_keys = data.keys()\n",
    "data_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994159c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67bfdd0c",
   "metadata": {},
   "source": [
    "3). Просмотрите данные, описание и названия признаков в датасете. Описание нужно вывести в виде привычного, аккуратно оформленного текста, без обозначений переноса строки, но с самими переносами и т.д.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a35d455",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596ce0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46e0463",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029086ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d359c7d6",
   "metadata": {},
   "source": [
    "4). Сколько классов содержит целевая переменная датасета? Выведите названия классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b30ecbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('classes total: ', data['target_names'].size)\n",
    "print('classes names: ', data['target_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed59af57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c594ecff",
   "metadata": {},
   "source": [
    "5). На основе данных датасета (они содержатся в двумерном массиве Numpy) и названий признаков создайте датафрейм под названием X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bfa72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(data['data'], columns=data['feature_names'])\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d56aec7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d33fab6",
   "metadata": {},
   "source": [
    "6). Выясните размер датафрейма X и установите, имеются ли в нем пропущенные значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996e0e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991f7880",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfea0549",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d3eed7a",
   "metadata": {},
   "source": [
    "7). Добавьте в датафрейм поле с классами вин в виде чисел, имеющих тип данных numpy.int64. Название поля - 'target'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9663ffca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['target'] = data.target\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50849a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bede0d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['target'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc718ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['target'] = data['target'].astype('int64')\n",
    "data['target'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87e4a45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96d5ab18",
   "metadata": {},
   "source": [
    "8). Постройте матрицу корреляций для всех полей X. Дайте полученному датафрейму название X_corr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af9375d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_corr = X.corr()\n",
    "X_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9df73f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47a18146",
   "metadata": {},
   "source": [
    "9). Создайте список high_corr из признаков, корреляция которых с полем target по абсолютному значению превышает 0.5 (причем, само поле target не должно входить в этот список)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db2997a",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_corr = X_corr.columns[(abs(X_corr['target']) > 0.5)&(X_corr.columns != 'target')]\n",
    "high_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea31faa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be4e2998",
   "metadata": {},
   "source": [
    "10). Удалите из датафрейма X поле с целевой переменной. Для всех признаков, названия которых содержатся в списке high_corr, вычислите квадрат их значений и добавьте в датафрейм X соответствующие поля с суффиксом '_2', добавленного к первоначальному названию признака. Итоговый датафрейм должен содержать все поля, которые, были в нем изначально, а также поля с признаками из списка high_corr, возведенными в квадрат. Выведите описание полей датафрейма X с помощью метода describe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3d498e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop('target', axis=1, inplace=True)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fa4c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.join(pd.DataFrame(\n",
    "    pow(X[high_corr], 2).values,\n",
    "    columns=[str(i) + '_2' for i in high_corr]\n",
    "))\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd484f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d08bc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
